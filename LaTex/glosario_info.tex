% !TeX root = ../tfg.tex
% !TeX encoding = utf8

\chapter*{Glosario informático}
\addcontentsline{toc}{chapter}{Glosario informático} % Añade el glosario a la tabla de contenidos

\begin{description} 
  \item[DDD] \textit{Deep Double Descent}.
  \item[$\mathcal{X}$] Espacio muestral que contiene todas las entradas posibles para un modelo.
  \item[$\mathcal{Y}$] Conjunto compuesto por todas las posibles salidas del modelo.
  \item[$\mathcal{L}$] Función de pérdida a minimizar por el modelo.
  \item[$\mathcal{D}$] Conjunto de datos de entrenamiento.
  \item[$\mathcal{H}$] Conjunto de hipótesis formado por las hipótesis candidatas y la función objetivo.
  \item[$\mathcal{A}$] Algoritmo de aprendizaje. 
  \item[$f$] Función objetivo. 
  \item[$\bar{g}$] Hipótesis ideal.
  \item[Sesgo] Error producido por la diferencia entre la hipótesis ideal y la función objetivo.
  \item[Varianza] Error producido por la diferencia entre la hipótesis elegida y la hipótesis ideal.
  \item[Descenso de gradiente] Método de optimización para minimizar una función de pérdida.
  \item[$\eta$] Tasa de aprendizaje o \textit{learning rate}.
  \item[$E_{out}$] Error fuera de la muestra o error de generalización. 
  \item[$E_{in}$] Error dentro de la muestra o error de entrenamiento.
  \item[Sweet spot] Mínimo del error de generalización según la sabiduría clásica.
  \item[$d_{vc}$] Dimensión de Vapnik-Chervonenkis.
  \item[$\mathcal{R}(\mathcal{K})$] Complejidad de Rademacher del conjunto $\mathcal{K}$.
  \item[Complejidad efectiva del modelo (EMC)] Máximo número de ejemplos de entrenamiento en el que el modelo obtiene un $E_{in}$ próximo a cero.
  \item[Región moderna o de interpolación] Zona en la que la capacidad del modelo supera su complejidad efectiva.
  \item[Umbral de interpolación] Punto en el que el modelo alcanza su complejidad efectiva.
  \item[Principio de Ockham] Principio filosófico que favorece las explicaciones más simples entre las posibles.
  \item[$w^{*}$] Solución óptima del problema de minimización de la función de pérdida.
  \item[Sesgo inductivo] Conjunto de supuestos que utiliza un algoritmo de aprendizaje para preferir unas hipótesis sobre otras.
  \item[Complejidad de Kolmogorov] Longitud del programa más corto que genera una hipótesis.
  \item[Conexión residual] Técnica que permite que la entrada pueda saltar capas de una red.
\end{description}

\endinput
