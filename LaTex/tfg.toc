\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman {iii}}{chapter*.3}%
\contentsline {chapter}{\nonumberline Resumen}{\es@scroman {v}}{chapter*.4}%
\babel@toc {english}{}\relax 
\contentsline {chapter}{\nonumberline Summary}{\es@scroman {vi}}{chapter*.5}%
\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\nonumberline \'{I}ndice de figuras}{\es@scroman {xi}}{chapter*.9}%
\contentsline {chapter}{\nonumberline \'{I}ndice de tablas}{\es@scroman {xii}}{chapter*.11}%
\contentsline {chapter}{\nonumberline Introducción}{\es@scroman {xiv}}{chapter*.12}%
\contentsline {section}{\numberline {1}Definición del problema}{\es@scroman {xv}}{section.0.1}%
\contentsline {section}{\numberline {2}Motivación}{\es@scroman {xvi}}{section.0.2}%
\contentsline {section}{\numberline {3}Objetivos}{\es@scroman {xvii}}{section.0.3}%
\contentsline {subsection}{\numberline {3.1}Objetivo matemático}{\es@scroman {xviii}}{subsection.0.3.1}%
\contentsline {subsection}{\numberline {3.2}Objetivo informático}{\es@scroman {xviii}}{subsection.0.3.2}%
\contentsline {section}{\numberline {4}Planificación del proyecto}{\es@scroman {xviii}}{section.0.4}%
\contentsline {part}{\numberline {I}Fundamentos Teóricos}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Probabilidad}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Espacios de probabilidad y $\sigma $-álgebras}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Variables aleatorias y esperanza}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Probabilidad condicional}{6}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Independencia de variables aleatorias}{8}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Propiedades de la esperanza y varianza}{12}{subsection.1.2.3}%
\contentsline {section}{\numberline {1.3}Distribuciones de probabilidad}{14}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Distribución Normal}{14}{subsection.1.3.1}%
\contentsline {chapter}{\numberline {2}Descomposición en valores singulares y pseudoinversa de una matriz}{16}{chapter.2}%
\contentsline {section}{\numberline {2.1}Vectores y matrices}{16}{section.2.1}%
\contentsline {section}{\numberline {2.2}SVD y pseudoinversa}{18}{section.2.2}%
\contentsline {chapter}{\numberline {3}Aprendizaje Automático y Aprendizaje Profundo}{23}{chapter.3}%
\contentsline {section}{\numberline {3.1}Fundamentos}{23}{section.3.1}%
\contentsline {section}{\numberline {3.2}Redes neuronales artificiales}{24}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Redes neuronales convolucionales}{25}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}Capa de convolución}{26}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}Capa de pooling}{28}{subsubsection.3.2.1.2}%
\contentsline {subsubsection}{\numberline {3.2.1.3}Capa totalmente conectada}{28}{subsubsection.3.2.1.3}%
\contentsline {subsubsection}{\numberline {3.2.1.4}Capa de activación}{29}{subsubsection.3.2.1.4}%
\contentsline {chapter}{\numberline {4}El dilema clásico del aprendizaje}{31}{chapter.4}%
\contentsline {section}{\numberline {4.1}Concepto de aprendizaje}{31}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Descenso de gradiente y aprendizaje}{32}{subsection.4.1.1}%
\contentsline {subsubsection}{\numberline {4.1.1.1}Aprendizaje en una red neuronal}{34}{subsubsection.4.1.1.1}%
\contentsline {section}{\numberline {4.2}Bias-variance tradeoff}{35}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Formulación matemática del $E_{out}$}{36}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Equilibrio clásico entre sesgo y varianza}{39}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Curva de aprendizaje}{40}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Underfitting y overfitting}{41}{section.4.4}%
\contentsline {part}{\numberline {II}Estado del Arte}{46}{part.2}%
\contentsline {chapter}{\numberline {5}Trabajos relacionados}{48}{chapter.5}%
\contentsline {section}{\numberline {5.1}Origen y primeras manifestaciones}{49}{section.5.1}%
\contentsline {section}{\numberline {5.2}El nacimiento del Deep Double Descent}{50}{section.5.2}%
\contentsline {section}{\numberline {5.3}Avances recientes}{51}{section.5.3}%
\contentsline {part}{\numberline {III}Desarrollo Teórico y Empírico}{54}{part.3}%
\contentsline {chapter}{\numberline {6}Análisis teórico del Deep Double Descent}{56}{chapter.6}%
\contentsline {section}{\numberline {6.1}Planteamiento teórico}{56}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Análisis intuitivo en un problema de mínimos cuadrados}{58}{subsection.6.1.1}%
\contentsline {section}{\numberline {6.2}Sesgo inductivo del descenso de gradiente}{63}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Problema de regresión}{63}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Problema de clasificación con datos separables}{67}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}Optimización en la zona sobreparametrizada}{69}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Elección de la mejor hipótesis}{74}{subsection.6.3.1}%
\contentsline {section}{\numberline {6.4}Resto de desarrollos a realizar}{76}{section.6.4}%
\contentsline {section}{\numberline {6.5}Aproximación no lineal}{76}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}Analogía con el deep double descent}{76}{subsection.6.5.1}%
\contentsline {section}{\numberline {6.6}Conclusión}{76}{section.6.6}%
\contentsline {chapter}{\numberline {7}Análisis empírico del Deep Double Descent}{77}{chapter.7}%
\contentsline {section}{\numberline {7.1}Materiales y métodos}{77}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Datasets}{77}{subsection.7.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.1}MNIST}{77}{subsubsection.7.1.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.2}CIFAR-10 y CIFAR-100}{77}{subsubsection.7.1.1.2}%
\contentsline {subsubsection}{\numberline {7.1.1.3}Flowers102}{78}{subsubsection.7.1.1.3}%
\contentsline {subsection}{\numberline {7.1.2}Arquitecturas utilizadas}{79}{subsection.7.1.2}%
\contentsline {subsubsection}{\numberline {7.1.2.1}2NN}{79}{subsubsection.7.1.2.1}%
\contentsline {subsubsection}{\numberline {7.1.2.2}ResNet-18 modificada}{80}{subsubsection.7.1.2.2}%
\contentsline {subsubsection}{\numberline {7.1.2.3}3CNN}{81}{subsubsection.7.1.2.3}%
\contentsline {subsection}{\numberline {7.1.3}Hiperparámetros}{82}{subsection.7.1.3}%
\contentsline {section}{\numberline {7.2}Experimentos}{82}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Aproximación polinómica de Legendre}{82}{subsection.7.2.1}%
\contentsline {subsubsection}{\numberline {7.2.1.1}Función cuadrática}{84}{subsubsection.7.2.1.1}%
\contentsline {subsubsection}{\numberline {7.2.1.2}Función exponencial}{84}{subsubsection.7.2.1.2}%
\contentsline {subsubsection}{\numberline {7.2.1.3}Función hiperbólica}{84}{subsubsection.7.2.1.3}%
\contentsline {subsection}{\numberline {7.2.2}Noise-wise double descent}{84}{subsection.7.2.2}%
\contentsline {subsection}{\numberline {7.2.3}Sample-wise double descent}{85}{subsection.7.2.3}%
\contentsline {section}{\numberline {7.3}Conclusión}{86}{section.7.3}%
\contentsline {part}{\numberline {IV}Conclusiones y Trabajos Futuros}{87}{part.4}%
\contentsline {chapter}{\numberline {8}Conclusiones}{89}{chapter.8}%
\contentsline {chapter}{\numberline {9}Trabajos futuros}{90}{chapter.9}%
\contentsline {chapter}{\numberline {A}Apéndice}{91}{appendix.Alph1}%
\contentsline {chapter}{\numberline {B}Apéndice}{93}{appendix.Alph2}%
\contentsline {chapter}{\numberline {C}Apéndice}{95}{appendix.Alph3}%
\contentsline {chapter}{Glosario}{97}{chapter*.60}%
\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{99}{chapter*.61}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
