\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman {iii}}{chapter*.3}%
\contentsline {chapter}{\nonumberline Resumen}{\es@scroman {v}}{chapter*.4}%
\babel@toc {english}{}\relax 
\contentsline {chapter}{\nonumberline Summary}{\es@scroman {vi}}{chapter*.5}%
\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\nonumberline \'{I}ndice de figuras}{\es@scroman {xi}}{chapter*.9}%
\contentsline {chapter}{\nonumberline \'{I}ndice de tablas}{\es@scroman {xiii}}{chapter*.11}%
\contentsline {chapter}{\nonumberline Introducción}{\es@scroman {xv}}{chapter*.12}%
\contentsline {section}{\numberline {1}Definición del problema}{\es@scroman {xvi}}{section.0.1}%
\contentsline {section}{\numberline {2}Motivación}{\es@scroman {xvii}}{section.0.2}%
\contentsline {section}{\numberline {3}Objetivos}{\es@scroman {xviii}}{section.0.3}%
\contentsline {subsection}{\numberline {3.1}Objetivo matemático}{\es@scroman {xviii}}{subsection.0.3.1}%
\contentsline {subsection}{\numberline {3.2}Objetivo informático}{\es@scroman {xix}}{subsection.0.3.2}%
\contentsline {section}{\numberline {4}Planificación del proyecto}{\es@scroman {xix}}{section.0.4}%
\contentsline {part}{\numberline {I}Fundamentos Teóricos}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Probabilidad}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Espacios de probabilidad y $\sigma $-álgebras}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Variables aleatorias y esperanza}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Probabilidad condicional}{6}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Independencia de variables aleatorias}{7}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Propiedades de la esperanza y varianza}{10}{subsection.1.2.3}%
\contentsline {section}{\numberline {1.3}Distribuciones de probabilidad}{12}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Distribución Normal}{12}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Distribución de Rademacher}{14}{subsection.1.3.2}%
\contentsline {chapter}{\numberline {2}Descomposición en Valores Singulares y Pseudoinversa de una Matriz}{15}{chapter.2}%
\contentsline {section}{\numberline {2.1}Vectores y matrices}{15}{section.2.1}%
\contentsline {section}{\numberline {2.2}SVD y pseudoinversa}{17}{section.2.2}%
\contentsline {chapter}{\numberline {3}Aprendizaje Automático y Aprendizaje Profundo}{21}{chapter.3}%
\contentsline {section}{\numberline {3.1}Fundamentos}{21}{section.3.1}%
\contentsline {section}{\numberline {3.2}Redes neuronales artificiales}{22}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Redes neuronales convolucionales}{23}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}Capa de convolución}{23}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}Capa de \textit {pooling}}{25}{subsubsection.3.2.1.2}%
\contentsline {subsubsection}{\numberline {3.2.1.3}Capa totalmente conectada}{26}{subsubsection.3.2.1.3}%
\contentsline {subsubsection}{\numberline {3.2.1.4}Capa de activación}{26}{subsubsection.3.2.1.4}%
\contentsline {chapter}{\numberline {4}El Dilema Clásico del Aprendizaje}{28}{chapter.4}%
\contentsline {section}{\numberline {4.1}Concepto de aprendizaje}{28}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Descenso de gradiente y aprendizaje}{29}{subsection.4.1.1}%
\contentsline {subsubsection}{\numberline {4.1.1.1}Optimizador Adam}{31}{subsubsection.4.1.1.1}%
\contentsline {subsubsection}{\numberline {4.1.1.2}Aprendizaje en una red neuronal}{32}{subsubsection.4.1.1.2}%
\contentsline {section}{\numberline {4.2}\textit {Bias-variance tradeoff}}{33}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Formulación matemática del $E_{out}$}{33}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Equilibrio clásico entre sesgo y varianza}{39}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Curva de aprendizaje}{40}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}\textit {Underfitting} y \textit {overfitting}}{42}{section.4.4}%
\contentsline {section}{\numberline {4.5}Marcos de generalización clásicos}{44}{section.4.5}%
\contentsline {part}{\numberline {II}Estado del Arte}{49}{part.2}%
\contentsline {chapter}{\numberline {5}Trabajos Relacionados}{51}{chapter.5}%
\contentsline {section}{\numberline {5.1}Origen y primeras manifestaciones}{52}{section.5.1}%
\contentsline {section}{\numberline {5.2}El nacimiento del \textit {Deep Double Descent}}{53}{section.5.2}%
\contentsline {section}{\numberline {5.3}Avances recientes}{54}{section.5.3}%
\contentsline {part}{\numberline {III}Análisis Teórico y Empírico}{57}{part.3}%
\contentsline {chapter}{\numberline {6}Análisis Teórico del Deep Double Descent}{59}{chapter.6}%
\contentsline {section}{\numberline {6.1}Planteamiento teórico}{59}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Análisis intuitivo en un problema de mínimos cuadrados}{62}{subsection.6.1.1}%
\contentsline {section}{\numberline {6.2}Convergencia del descenso de gradiente}{65}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Problema de regresión}{66}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Problema de clasificación con datos separables}{69}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}Optimización en la zona sobreparametrizada}{71}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}El impacto del sesgo inductivo en la selección de hipótesis}{76}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}PAC-Bayes y límite de hipótesis numerables}{80}{subsection.6.3.2}%
\contentsline {section}{\numberline {6.4}Aproximación no lineal}{81}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Aproximación en un espacio de Hilbert}{82}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Aproximación altamente no lineal}{84}{subsection.6.4.2}%
\contentsline {subsubsection}{\numberline {6.4.2.1}Selección óptima de bases}{85}{subsubsection.6.4.2.1}%
\contentsline {subsubsection}{\numberline {6.4.2.2}Aproximación usando $n$ términos de un diccionario}{86}{subsubsection.6.4.2.2}%
\contentsline {subsection}{\numberline {6.4.3}Analogía con el \textit {Deep Double Descent}}{88}{subsection.6.4.3}%
\contentsline {section}{\numberline {6.5}Discusión final}{89}{section.6.5}%
\contentsline {chapter}{\numberline {7}Análisis Empírico del Deep Double Descent}{91}{chapter.7}%
\contentsline {section}{\numberline {7.1}Materiales y métodos}{91}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}\textit {Datasets}}{91}{subsection.7.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.1}MNIST}{91}{subsubsection.7.1.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.2}CIFAR10 y CIFAR100}{91}{subsubsection.7.1.1.2}%
\contentsline {subsection}{\numberline {7.1.2}Protocolo de validación experimental}{92}{subsection.7.1.2}%
\contentsline {subsection}{\numberline {7.1.3}Arquitecturas utilizadas}{93}{subsection.7.1.3}%
\contentsline {subsubsection}{\numberline {7.1.3.1}2NN}{93}{subsubsection.7.1.3.1}%
\contentsline {subsubsection}{\numberline {7.1.3.2}3CNN}{94}{subsubsection.7.1.3.2}%
\contentsline {subsubsection}{\numberline {7.1.3.3}ResNet18 modificada}{95}{subsubsection.7.1.3.3}%
\contentsline {subsection}{\numberline {7.1.4}Hiperparámetros}{96}{subsection.7.1.4}%
\contentsline {section}{\numberline {7.2}Experimentos}{97}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Entornos de desarrollo y ejecución}{97}{subsection.7.2.1}%
\contentsline {subsection}{\numberline {7.2.2}Aproximación polinómica}{99}{subsection.7.2.2}%
\contentsline {subsubsection}{\numberline {7.2.2.1}Función lineal}{100}{subsubsection.7.2.2.1}%
\contentsline {subsubsection}{\numberline {7.2.2.2}Función hiperbólica}{103}{subsubsection.7.2.2.2}%
\contentsline {subsubsection}{\numberline {7.2.2.3}Discusión}{104}{subsubsection.7.2.2.3}%
\contentsline {subsection}{\numberline {7.2.3}\textit {Noise-wise double descent}}{105}{subsection.7.2.3}%
\contentsline {subsubsection}{\numberline {7.2.3.1}Discusión}{107}{subsubsection.7.2.3.1}%
\contentsline {subsection}{\numberline {7.2.4}\textit {Sample-wise double descent}}{107}{subsection.7.2.4}%
\contentsline {subsubsection}{\numberline {7.2.4.1}Ratio parámetros/ejemplos}{108}{subsubsection.7.2.4.1}%
\contentsline {subsubsection}{\numberline {7.2.4.2}Discusión}{109}{subsubsection.7.2.4.2}%
\contentsline {subsection}{\numberline {7.2.5}\textit {Model \& Epoch-wise double descent}}{110}{subsection.7.2.5}%
\contentsline {subsubsection}{\numberline {7.2.5.1}2NN}{110}{subsubsection.7.2.5.1}%
\contentsline {subsubsection}{\numberline {7.2.5.2}3CNN}{111}{subsubsection.7.2.5.2}%
\contentsline {subsubsection}{\numberline {7.2.5.3}ResNet18 modificada}{113}{subsubsection.7.2.5.3}%
\contentsline {subsubsection}{\numberline {7.2.5.4}Discusión}{114}{subsubsection.7.2.5.4}%
\contentsline {subsection}{\numberline {7.2.6}\textit {Width vs Depth double descent}}{115}{subsection.7.2.6}%
\contentsline {subsubsection}{\numberline {7.2.6.1}Discusión}{116}{subsubsection.7.2.6.1}%
\contentsline {section}{\numberline {7.3}Discusión comparativa global}{116}{section.7.3}%
\contentsline {part}{\numberline {IV}Conclusiones y Trabajos Futuros}{119}{part.4}%
\contentsline {chapter}{\numberline {8}Conclusiones}{121}{chapter.8}%
\contentsline {chapter}{\numberline {9}Trabajos futuros}{123}{chapter.9}%
\contentsline {part}{\numberline {V}Anexos}{124}{part.5}%
\contentsline {chapter}{\numberline {A}Detalles Matemáticos Adicionales}{126}{appendix.Alph1}%
\contentsline {chapter}{\numberline {B}Experimentos Adicionales: Hiperparámetros}{129}{appendix.Alph2}%
\contentsline {chapter}{\numberline {C}Descenso de Gradiente en un Problema OLS}{131}{appendix.Alph3}%
\contentsline {chapter}{\numberline {D}Irregularidades en la Dinámica del Error}{132}{appendix.Alph4}%
\contentsline {chapter}{Glosario matemático}{135}{chapter*.99}%
\contentsline {chapter}{Glosario informático}{137}{chapter*.100}%
\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{139}{chapter*.101}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
