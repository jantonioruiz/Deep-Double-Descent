% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Summary
%*******************************************************

\selectlanguage{english}
\chapter{Summary}

\noindent\textbf{Keywords:} Machine Learning, Deep Learning, Artificial Intelligence, Bias-Variance Tradeoff, Non-Linear Approximation, Generalization Frameworks, Explainability

\

Machine learning and, by extension, deep learning, has become a fundamental tool in many fields, playing a decisive role in complementing and supporting the human expert in numerous tasks. However, the training of increasingly complex models has recently revealed unexpected behaviors in their performance, among which the phenomenon known as \emph{Deep Double Descent} stands out. This behavior challenges the classical wisdom of learning by showing that the relationship between model complexity and performance does not conform to the learning curves predicted by conventional theory.

The classical concepts of learning are insufficient to explain certain emerging phenomena. In fact, some of them, such as the bias-variance trade-off, seem to contradict these new trends. This event reveals a significant gap between theoretical knowledge and the empirical findings recorded in recent observations, which reminds us that the field of AI is constantly evolving, and that advances in this discipline do not occur at the same pace on the theoretical and practical levels.

In this Final Degree Project, we will focus on exposing the underlying computational and mathematical principles necessary to understand the \emph{Deep Double Descent}, starting from the classical framework of the bias-variance trade-off, for which it will be necessary to draw on notions of probability and statistics. Likewise, concepts related to matrix algebra, which are essential for a deeper understanding, will be reviewed and introduced. However, given the common perception of neural networks as “black boxes”, attributed to the difficulty of interpreting their inner workings, this paper aims to analyze and contribute to a better understanding of the general behavior of deep neural networks.

This study focuses on the definition of new generalization frameworks, known as inductive biases, that provide explanability beyond what is offered by classical theory, thus unifying traditional concepts with modern approaches. In addition, the nonlinear approach is used as a complementary way to reinforce these frameworks from a more mathematical and formal perspective.

Through various experiments, both in simple architectures and in advanced convolutional architectures, such as ResNet, it is shown that the \emph{Deep Double Descent} not only improves the performance of the models in classification and regression tasks, but also suggests that the solutions obtained tend to be increasingly simpler, following the philosophy of Ockham's razor principle.

In conclusion, this work is not only focused on providing an explanation of the \emph{Deep Double Descent}, but also constitutes an advance towards the understanding and explainability of new generalization trends. This behavior points towards a new direction in machine learning, based on the idea of \emph{«the bigger, the better»}, without forgetting that this brings with it significant computational efficiency and scalability challenges, which continues to underscore the need to balance technological ambition and practical feasibility.

\clearpage
\thispagestyle{empty}
\mbox{}
\newpage
% Al finalizar el resumen en inglés, volvemos a seleccionar el idioma español para el documento
\selectlanguage{spanish} 
\endinput
