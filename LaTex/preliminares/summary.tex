% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Summary
%*******************************************************

\selectlanguage{english}
\chapter{Summary}

\noindent\textbf{Keywords:} Machine Learning, Deep Learning, Artificial Intelligence, Bias-Variance, Non-Linear Approximation, Generalization Frameworks, Explainability

\

Machine learning, particularly deep learning, has become a fundamental tool in many fields, playing a decisive role in complementing and even replacing human work in various contexts. However, the training of increasingly complex models has recently revealed unexpected behaviors in their performance, among which the phenomenon known as \emph{Deep Double Descent} stands out. This behavior challenges the classical wisdom of learning by showing that the relationship between model complexity and performance does not conform to the learning curves predicted by conventional theory.

The classical concepts of learning are insufficient to explain certain emerging phenomena. In fact, some of them, such as the bias-variance trade-off, seem to contradict these new trends. This event reveals a significant gap between theoretical knowledge and the empirical findings recorded in recent observations, which reminds us that the field of AI is constantly evolving, and that advances in this discipline do not occur in parallel between theory and practice.

In this Final Degree Project, we will focus on exposing the underlying computational and mathematical principles necessary to understand the \emph{Deep Double Descent}, starting from the classical framework of the bias-variance trade-off, for which it will be necessary to draw on notions of probability and statistics. Likewise, concepts related to matrix algebra, which are essential for a deeper understanding, will be reviewed and introduced. However, given the common perception of neural networks as «black boxes», due to the fact that their inner workings are not precisely known, we will work in an alternative way by defining techniques that will help to explain their behavior.

This study focuses on the definition of new generalization frameworks, known as inductive biases, that provide explanability beyond what is offered by classical theory, thus unifying traditional concepts with modern approaches. In addition, the nonlinear approach is used as a complementary way to reinforce these frameworks from a more mathematical and formal perspective.

Through various experiments, both in simple architectures and in advanced convolutional architectures such as ResNet, it is shown that this phenomenon not only improves the performance of the models in classification and regression tasks, but also suggests that the solutions obtained tend to be increasingly simpler, following the philosophy of Ockham's razor principle.

In conclusion, this work is not only focused on providing an explanation of the \emph{Deep Double Descent}, but also constitutes an advance towards the understanding and explainability of the new generalization trends currently observed. This behavior suggests a new perspective on the direction that machine learning should take to achieve increasingly accurate results, based on the use of models with increasing capacity, following the logic that, in this context, \emph{«bigger is better»}.

\clearpage
\thispagestyle{empty}
\mbox{}
\newpage
% Al finalizar el resumen en inglés, volvemos a seleccionar el idioma español para el documento
\selectlanguage{spanish} 
\endinput
