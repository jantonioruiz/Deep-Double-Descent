% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Resumen
%*******************************************************

\chapter{Resumen}

\noindent\textbf{Palabras clave:} Aprendizaje Automático, Aprendizaje Profundo, Inteligencia Artificial, Sesgo-Varianza, Aproximación No Lineal, Visión por Computador

\

El aprendizaje automático, y en particular el aprendizaje profundo, se ha convertido en una herramienta fundamental en numerosos ámbitos, desempeñando un papel determinante al complementar e incluso reemplazar las labores humanas en diversos contextos. No obstante, el entrenamiento de modelos cada vez más complejos ha revelado, recientemente, comportamientos inesperados en su rendimiento, entre los cuales destaca el fenómeno conocido como \emph{Deep Double Descent}. Este comportamiento desafía la sabiduría clásica del aprendizaje, al evidenciar que la relación entre la complejidad del modelo y su rendimiento no se ajusta a las curvas tradicionales previstas por la teoría convencional.\newline

En el enfoque clásico del aprendizaje automático, aumentar la capacidad de un modelo mejora su capacidad para ajustarse a los datos, pero eventualmente conduce al sobreajuste, momento en el cual el rendimiento del modelo comienza a empeorar. En contraposición, hallazgos recientes han demostrado que, a medida que el modelo sigue aumentando su capacidad más allá de ese sobreajuste, su rendimiento comienza a mejorar nuevamente, creando un segundo descenso que rompe con la intuición clásica. Este comportamiento revela una brecha significativa entre los conocimientos teóricos y los resultados empíricos observados en la actualidad, lo cual nos recuerda que el campo de la inteligencia artificial está en constante evolución, y que los avances en esta disciplina no se producen de forma paralela entre la teoría y la práctica.\newline

En este TFG, nos centraremos en exponer los principios informáticos y matemáticos esenciales para comprender el \emph{Deep Double Descent}, partiendo del marco clásico del equilibrio entre sesgo y varianza, para lo cual será necesario recurrir a nociones de teoría de la probabilidad y estadística. Asimismo, se revisarán e introducirán conceptos relativos al álgebra matricial que resultan imprescindibles para entenderlo en profundidad. De esta manera, el objetivo principal del trabajo consiste en dar a conocer el conocimiento disponible hasta la fecha para explicar este suceso, complementándolo con la realización de diversos experimentos que respalden empíricamente la información teórica, con el fin de discutir algunas de las preguntas abiertas que plantea la literatura actual.\newline

Por otro lado, se desarrollará la teoría de la aproximación no lineal, dada su a priori y significativa relación con el \emph{Deep Double Descent}, resaltando las distintas analogías que comparten. Con todo ello, se busca contribuir a la construcción de un puente que permita reconciliar la sabiduría clásica con los descubrimientos modernos, favoreciendo así una comprensión más unificada del aprendizaje automático contemporáneo.\newline