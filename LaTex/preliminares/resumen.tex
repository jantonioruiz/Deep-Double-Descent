% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Resumen
%*******************************************************

\chapter{Resumen}

\noindent\textbf{Palabras clave:} Aprendizaje Automático, Aprendizaje Profundo, Inteligencia Artificial, Sesgo-Varianza, Aproximación No Lineal, Marcos de Generalización, Explicabilidad

\

El aprendizaje automático, y en particular el aprendizaje profundo, se ha convertido en una herramienta fundamental en numerosos ámbitos, desempeñando un papel determinante al complementar e incluso reemplazar las labores humanas en diversos contextos. No obstante, el entrenamiento de modelos cada vez más complejos ha revelado, recientemente, comportamientos inesperados en su rendimiento, entre los cuales destaca el fenómeno conocido como \emph{Deep Double Descent}. Esto desafía la sabiduría clásica del aprendizaje, al evidenciar que la relación entre la complejidad del modelo y su rendimiento no se ajusta a las curvas previstas por la teoría convencional.

Los conceptos clásicos del aprendizaje resultan insuficientes para explicar ciertos fenómenos emergentes. De hecho, algunos, como el equilibrio entre sesgo y varianza, parecen contradecir estas nuevas tendencias. Este suceso revela una brecha significativa entre los conocimientos teóricos y los resultados empíricos observados en la actualidad, lo cual nos recuerda que el campo de la inteligencia artificial está en constante evolución, y que los avances en esta disciplina no se producen de forma paralela entre la teoría y la práctica.

En este TFG nos centraremos en exponer los principios informáticos y matemáticos subyacentes necesarios para comprender el \emph{Deep Double Descent}, partiendo del marco clásico del equilibrio entre sesgo y varianza, para lo cual será necesario recurrir a nociones de probabilidad y estadística. Asimismo, se revisarán e introducirán conceptos relativos al álgebra matricial que resultan imprescindibles para un entendimiento más profundo. No obstante, dada la percepción común de las redes neuronales como «cajas negras», debido a que no se conoce con precisión su funcionamiento interno, se trabaja de manera alternativa mediante la definición de técnicas que ayuden a aportar explicabilidad a dicho comportamiento.

Este estudio se centra en la definición de nuevos marcos de generalización, conocidos como \emph{sesgos inductivos}, que proporcionen explicabilidad más allá de lo que ofrece la teoría clásica, unificando así los conceptos tradicionales con los enfoques modernos. Además, se recurre a la aproximación no lineal como vía complementaria para reforzar dichos marcos desde una perspectiva más matemática y formal.

A través de diversos experimentos, tanto en arquitecturas simples como en arquitecturas convolucionales avanzadas como ResNet, se demuestra que este suceso no solo mejora el rendimiento de los modelos en tareas de clasificación y regresión, sino que también sugiere que las soluciones obtenidas tienden a ser cada vez más simples, siguiendo la filosofía del principio de la navaja de Ockham.

En conclusión, este trabajo no se centra únicamente en ofrecer una explicación del \emph{Deep Double Descent}, sino que también constituye un avance hacia la comprensión y explicabilidad de las tendencias de generalización observadas en la actualidad. Este comportamiento sugiere una nueva perspectiva sobre la dirección que debe tomar el aprendizaje automático para lograr resultados cada vez más precisos, fundamentada en el uso de modelos con una capacidad creciente, siguiendo la lógica de que, en este contexto, \emph{«cuanto más grande, mejor»}.

