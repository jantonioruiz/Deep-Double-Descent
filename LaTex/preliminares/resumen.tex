% !TeX root = ../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Resumen
%*******************************************************

\chapter{Resumen}

\noindent\textbf{Palabras clave:} Aprendizaje Automático, Aprendizaje Profundo, Inteligencia Artificial, Equilibrio Sesgo-Varianza, Aproximación No Lineal, Marcos de Generalización, Explicabilidad

\

El aprendizaje automático y, por extensión, el aprendizaje profundo, se ha convertido en una herramienta fundamental en numerosos ámbitos, desempeñando un papel determinante al complementar y dar apoyo al experto humano en numerosas tareas. No obstante, el entrenamiento de modelos cada vez más complejos ha revelado, recientemente, comportamientos inesperados en su rendimiento, entre los cuales destaca el fenómeno conocido como \emph{Deep Double Descent}. Esto desafía la sabiduría clásica del aprendizaje, al evidenciar que la relación entre la complejidad del modelo y su rendimiento no se ajusta a las curvas previstas por la teoría convencional.

Los conceptos clásicos del aprendizaje resultan insuficientes para explicar ciertos fenómenos emergentes. De hecho, algunos, como el equilibrio entre sesgo y varianza, parecen contradecir estas nuevas tendencias. Este suceso revela una brecha significativa entre los conocimientos teóricos y los resultados empíricos observados en la actualidad, lo cual nos recuerda que el campo de la inteligencia artificial está en constante evolución, y que los avances en esta disciplina no se realizan a la misma velocidad a nivel teórico y práctico.

En este TFG nos centraremos en exponer los principios informáticos y matemáticos subyacentes necesarios para comprender el \emph{Deep Double Descent}, partiendo del marco clásico del equilibrio entre sesgo y varianza, para lo cual será necesario recurrir a nociones de probabilidad y estadística. Asimismo, se revisarán e introducirán conceptos relativos al álgebra matricial que resultan imprescindibles para un entendimiento más profundo. Sin embargo, dada la percepción común de las redes neuronales como «cajas negras», atribuida a la dificultad de interpretar su funcionamiento interno, en este trabajo se pretende analizar y contribuir a una mejor comprensión del comportamiento general de redes neuronales profundas.

Este estudio se centra en la definición de nuevos marcos de generalización, conocidos como sesgos inductivos \textit{(inductive bias)}, que proporcionen explicabilidad más allá de lo que ofrece la teoría clásica, unificando así los conceptos tradicionales con los enfoques modernos. Además, se recurre a la aproximación no lineal como vía complementaria para reforzar dichos marcos desde una perspectiva más matemática y formal.

A través de diversos experimentos, tanto en arquitecturas simples como en arquitecturas convolucionales avanzadas, como ResNet, se demuestra que el \emph{Deep Double Descent} no solo mejora el rendimiento de los modelos en tareas de clasificación y regresión, sino que también sugiere que las soluciones obtenidas tienden a ser cada vez más simples, siguiendo la filosofía del principio de la navaja de Ockham.

En conclusión, este trabajo no se centra únicamente en ofrecer una explicación del \emph{Deep Double Descent}, sino que también constituye un avance hacia la comprensión y explicabilidad de las nuevas tendencias de generalización. Este comportamiento apunta hacia una nueva dirección en el aprendizaje automático, basada en la idea de \emph{«cuanto más grande, mejor»}, sin olvidar que esto conlleva importantes desafíos de eficiencia computacional y escalabilidad, lo que sigue subrayando la necesidad de equilibrar ambición tecnológica y viabilidad práctica.